{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Danicoder/Especializacion_IA_BigData/blob/main/Clasificador_flores_mejorado.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "\n",
        "from keras import Sequential\n",
        "from keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "tr0WcxAO4bZX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Descargar y extraer el dataset\n",
        "dataset_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\n",
        "data_dir = tf.keras.utils.get_file('flower_photos', origin=dataset_url, cache_dir='.', untar=True) #untar=True creó una subcarpeta adicional llamada flower_photos\n",
        "data_dir = os.path.join(os.path.dirname(data_dir), 'flower_photos')  # Obtener ruta correcta\n",
        "test_dir = tf.keras.utils.get_file('flower_photos', origin=dataset_url, cache_dir='.', untar=True)\n",
        "test_dir = os.path.join(os.path.dirname(test_dir), 'flower_photos_test')"
      ],
      "metadata": {
        "id": "Fx9d_snu4cUG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CbzDcy3luJRI",
        "outputId": "0a78fdb0-3b1d-4a96-9462-7b351159aa7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "./datasets/flower_photos_test\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificar si la carpeta \"flower_photos\" existe dentro del directorio de datos\n",
        "flower_photos_dir = os.path.join(data_dir, \"flower_photos\")\n",
        "\n",
        "# Actualizar data_dir para que apunte a flower_photos si existe\n",
        "if os.path.exists(flower_photos_dir):\n",
        "    data_dir = flower_photos_dir  # Actualizamos a la ruta correcta\n",
        "    print(\"Ruta actualizada a:\", data_dir)\n",
        "else:\n",
        "    print(\"La carpeta 'flower_photos' no existe en el directorio de datos.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYcXakzVDacG",
        "outputId": "a34b7f20-4960-40b4-8aee-c5adca6774b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ruta actualizada a: ./datasets/flower_photos/flower_photos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificar si la carpeta \"flower_photos\" existe dentro del directorio de datos\n",
        "flower_photos_test = os.path.join(test_dir, \"flower_photos\")\n",
        "\n",
        "# Actualizar data_dir para que apunte a flower_photos si existe\n",
        "if os.path.exists(flower_photos_test):\n",
        "    test_dir = flower_photos_test  # Actualizamos a la ruta correcta\n",
        "    print(\"Ruta actualizada a:\", test_dir)\n",
        "else:\n",
        "    print(\"La carpeta 'flower_photos' no existe en el directorio de datos.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JlgiWYYVnYbA",
        "outputId": "60fc10b1-043e-4c2a-f13e-96a2a18c16cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "La carpeta 'flower_photos' no existe en el directorio de datos.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Parámetros del dataset\n",
        "batch_size = 32\n",
        "img_height = 160\n",
        "img_width = 160\n",
        "\n",
        "# Configurar ImageDataGenerator para cargar imágenes por lotes\n",
        "# ImageDataGenerator para entrenamiento y validación (con división de 80% y 20%)\n",
        "train_datagen = ImageDataGenerator(rescale=1.0/255., validation_split=0.2)\n",
        "# ImageDataGenerator para test (con división de 20%)\n",
        "test_datagen = ImageDataGenerator(rescale=1.0/255.)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='training' # División para entrenamiento (80%)\n",
        ")\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='validation' # División para validación (20%)\n",
        ")\n",
        "# Para el conjunto de test, no usamos subset ni validation_split\n",
        "test_generator =  test_datagen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical'\n",
        "    subset='validation'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "ns6VjTPx7UdX",
        "outputId": "f0eca87a-fbee-4f83-8209-7c6d099f0057"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax. Perhaps you forgot a comma? (<ipython-input-10-4c944d4a9e94>, line 32)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-10-4c944d4a9e94>\"\u001b[0;36m, line \u001b[0;32m32\u001b[0m\n\u001b[0;31m    class_mode='categorical'\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ENTRENAMIENTO DEL MODELO Y AJUSTE"
      ],
      "metadata": {
        "id": "TpQAQ14dTG5t"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Z90k539S838"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Obtener un lote de imágenes del generador\n",
        "images, labels = next(train_generator)\n",
        "\n",
        "# Visualizar las primeras 5 imágenes\n",
        "plt.figure(figsize=(10, 10))\n",
        "for i in range(5):\n",
        "    ax = plt.subplot(1, 5, i + 1)\n",
        "    plt.imshow(images[i])  # Muestra la imagen\n",
        "    plt.axis(\"off\")  # No mostrar los ejes\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data augmentation"
      ],
      "metadata": {
        "id": "BZoUmgMDT26I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_augmentation = Sequential([\n",
        "    layers.RandomFlip(\"horizontal\", # Volteo aleatorio\n",
        "        input_shape=(img_height,\n",
        "                     img_width,\n",
        "                     3)),\n",
        "    layers.RandomRotation(0.2), # Rotación aleatoria (hasta 288°)\n",
        "    layers.RandomZoom(0.2),\n",
        "    layers.RandomBrightness(0.5)                   # Ajuste de brillo aleatorio (mas o menos 20%)\n",
        "  ])"
      ],
      "metadata": {
        "id": "6OnLUKoqT4DF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Arquitectura del modelo con MobileNetV2"
      ],
      "metadata": {
        "id": "z1bFPORFf4DK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = tf.keras.applications.MobileNetV2(input_shape=(160, 160, 3),\n",
        "                                               include_top=False,\n",
        "                                               weights='imagenet')"
      ],
      "metadata": {
        "id": "CLGBW2Hdf248"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vgg16_conv_base = VGG16(\n",
        "    input_shape = (\n",
        "        img_height,img_width,3),  # Tamaño de la imágen de entrada con 160 canales * 3 (rojo,verde y azul)\n",
        "        include_top=False,        # excluye la capa final\n",
        "        weights = 'imagenet')     # conjunto de datos\n",
        "\n",
        "vgg16_conv_base.summary()"
      ],
      "metadata": {
        "id": "GzerJo_ofoVN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Capas"
      ],
      "metadata": {
        "id": "iEwDvmdea05v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Entrenar modelo"
      ],
      "metadata": {
        "id": "gfSxI1t0Z-8n"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Zeg8zsqXCsm"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(base_model)\n",
        "model.add(data_augmentation)\n",
        "\n",
        "# evito sobreajuste\n",
        "model.add(Dropout(0.2))\n",
        "# Aplanar las características\n",
        "model.add(Flatten())\n",
        "\n",
        "# Capa densa con 128 neuronas\n",
        "model.add(Dense(128, activation='relu'))\n",
        "# Capa de salida con 5 neuronas\n",
        "model.add(Dense(5, activation='softmax'))\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compilar modelo"
      ],
      "metadata": {
        "id": "D86vMG9rWe7W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "              optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "unsJNODTWc2o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "      train_generator,\n",
        "      epochs=10,\n",
        "      validation_data=validation_generator,\n",
        "      verbose=1,\n",
        "      callbacks = [\n",
        "        tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3),\n",
        "        tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=1e-6),\n",
        "        tf.keras.callbacks.ModelCheckpoint(filepath='modelo_flowers.h5', monitor='val_loss', save_best_only=True)\n",
        "      ]\n",
        ")"
      ],
      "metadata": {
        "id": "zv02qxgI4cKo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluo el modelo"
      ],
      "metadata": {
        "id": "a5xx-35RaVtH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_generator = test_datagen.flow_from_directory(\n",
        "    data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='sparse'  # Change class_mode to 'sparse'\n",
        ")\n"
      ],
      "metadata": {
        "id": "dCc_jEQoaTG3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualizar las Curvas de accuracy y val_accuracy"
      ],
      "metadata": {
        "id": "6vPEmzqycMkT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Graficar la precisión y la precisión de validación\n",
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "# Accuracy de entrenamiento\n",
        "plt.plot(history.history['accuracy'], label='Training accuracy')\n",
        "\n",
        "# Accuracy de validación\n",
        "plt.plot(history.history['val_accuracy'], label='Validation accuracy')\n",
        "\n",
        "# Añadir etiquetas\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "# Mostrar la gráfica\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2iYKUoLP4cHx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transfer Learning (Aumenta la presición del la red)"
      ],
      "metadata": {
        "id": "gdShm0YtauoX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fine-Tuning: Descongelar Capas del Modelo Base"
      ],
      "metadata": {
        "id": "kWZJfxTNdKRU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vgg16_conv_base.trainable = True # no entrenar capa convulcional de VGG16\n",
        "\n",
        "# Define TrainingConfig as a simple class to hold configuration\n",
        "class TrainingConfig:\n",
        "    LAYERS_FINE_TUNE = 8\n",
        "\n",
        "num_layers_fine_tune = TrainingConfig.LAYERS_FINE_TUNE\n",
        "num_layers = len(vgg16_conv_base.layers)\n",
        "\n",
        "# Congelamos las capas que no vamos a entrenar\n",
        "for layer in vgg16_conv_base.layers[:num_layers - num_layers_fine_tune]:\n",
        "    print(f\"FREEZING LAYER: {layer}\")\n",
        "    layer.trainable = False\n",
        "\n",
        "print(\"\\n\")\n",
        "print(f\"Configured to fine tune the last {num_layers_fine_tune} layers of the base model.\")\n",
        "print(\"\\n\")\n",
        "\n",
        "# Verificamos el estado de las capas\n",
        "print(vgg16_conv_base.summary())\n",
        "\n"
      ],
      "metadata": {
        "id": "fYY4PDUg4bTu"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Te damos la bienvenida a Colaboratory",
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}